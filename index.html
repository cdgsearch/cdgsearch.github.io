<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Research Paper Title - Your Name</title>
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&display=swap" rel="stylesheet">
    <script src="script.js"></script>
</head>
<body>
    <main class="container">
        <!-- Header Section -->
        <header class="paper-header">
            <h1 class="paper-title">Compositional Diffusion with Guided search for Long-Horizon Planning</h1>
            <div class="author-info">
                <!-- <p class="authors">
                    <span class="author">Your Name<sup>1</sup></span>,
                    <span class="author">Co-Author Name<sup>2</sup></span>
                </p>
                <p class="affiliations">
                    <span class="affiliation"><sup>1</sup>Your Institution</span>
                    <span class="affiliation"><sup>2</sup>Co-Author Institution</span>
                </p> -->
                <!-- <p class="contact">
                    <a href="mailto:your.email@institution.edu">your.email@institution.edu</a>
                </p> -->
            </div>
        </header>

        <!-- Teaser Figure -->
        <section class="content-section">
            <figure class="media-figure">
                <img src="./figures/teaser.png" alt="Teaser Figure" class="teaser-image">
            </figure>
        </section>

        <!-- Abstract Section -->
        <section class="abstract">
            <h2>Abstract</h2>
            <p>
                Solving long-horizon goal-directed planning problems requires reasoning about both global structure 
                <i>(what)</i> and local feasibility <i>(how)</i>. This challenge is amplified when only short-horizon 
                data is available, yet arises broadly across domainsâ€”including panoramic image synthesis, long-video 
                generation, and multi-stage robot manipulation. A natural solution is to compose local plans into a 
                coherent global plan, but traditional methods either rely on symbolic/geometric specifications or fail 
                to generalize when local distributions are highly multimodal. We propose Compositional Diffusion with 
                Guided Search (CDGS), a unified generative framework that embeds search within the denoising process 
                of compositional diffusion. This inference-time scaling procedure enforces temporal consistency, prunes 
                infeasible paths, and harmonizes local segments, producing globally coherent and feasible solutions 
                without explicit symbolic models. CDGS matches oracle performance on seven robot manipulation tasks 
                and outperforms baselines lacking compositionality or trained only on long-horizon data. We further 
                show that CDGS's effective local-to-global message passing enables coherent generation of text-guided 
                panoramic images and long videos. 
            </p>
        </section>

        <!-- Method Figure -->
        <section class="content-section">
            <h2>Method</h2>
            <p>
                Our approach consists of three main components that work together to achieve superior performance. 
                The overall methodology is illustrated in the figure below.
            </p>
            
            <figure class="media-figure">
                <img src="./figures/method.png" alt="Method Overview" class="large-image">
            </figure>
        </section>

        <!-- Results Section -->
        <section class="content-section">
            <h2>Results</h2>
            <p>
                We evaluate our approach across three key domains that demonstrate the versatility and effectiveness of our method. 
                Each evaluation category showcases different aspects of our algorithm's capabilities.
            </p>

            <!-- Evaluation Overview -->
            <div class="evaluation-overview">
                <div class="eval-category">
                    <h3>ðŸ¤– Long Horizon Manipulation Tasks</h3>
                    <p>Complex robotic manipulation sequences requiring long-horizon planning and reasoning about inter-step dependencies.</p>
                </div>
                <div class="eval-category">
                    <h3>ðŸŒ„ Panoramic Image Generation</h3>
                    <p>High-resolution panoramic image synthesis (512 x 4608) with seamless stitching and detail preservation.</p>
                </div>
                <div class="eval-category">
                    <h3>ðŸŽ¬ Long Video Generation</h3>
                    <p>Extended video sequence generation upto 350 frames while maintaining temporal and subject consistencies.</p>
                </div>
            </div>

            <!-- 1. Long Horizon Manipulation Tasks -->
            <div class="results-category">
                <h3>1. Long Horizon Manipulation Tasks</h3>
                <!-- <p>
                    Our method demonstrates superior performance in complex manipulation tasks that require extended 
                    planning horizons and precise execution. We present two representative examples showcasing 
                    different aspects of manipulation capabilities.
                </p> -->
                
                <div class="manipulation-videos">
                    <div class="video-pair">
                        <figure class="media-figure manipulation-demo">
                            <video class="demo-video" preload="metadata">
                                <source src="videos/rearrangement_memory.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <!-- <figcaption>
                                <strong>Video 1:</strong> Multi-step object assembly task demonstrating long-horizon planning 
                                with precise manipulation and error recovery capabilities.
                            </figcaption> -->
                        </figure>

                        <figure class="media-figure manipulation-demo">
                            <video class="demo-video" preload="metadata">
                                <source src="videos/rearrangement_push.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <!-- <figcaption>
                                <strong>Video 2:</strong> Complex kitchen task involving multiple tools and sequential operations 
                                showcasing adaptive behavior and robust execution.
                            </figcaption> -->
                        </figure>
                    </div>
                </div>

                <!-- <div class="performance-metrics">
                    <div class="metric-item">
                        <span class="metric-value">94.2%</span>
                        <span class="metric-label">Success Rate</span>
                    </div>
                    <div class="metric-item">
                        <span class="metric-value">3.7x</span>
                        <span class="metric-label">Speed Improvement</span>
                    </div>
                    <div class="metric-item">
                        <span class="metric-value">15.8s</span>
                        <span class="metric-label">Avg. Planning Time</span>
                    </div>
                </div> -->
            </div>

            <!-- 2. Panoramic Image Generation -->
            <div class="results-category">
                <h3>2. Panoramic Image and Long Video Generation</h3>
                <!-- <p>
                    Our approach excels at generating high-quality panoramic images with seamless stitching and 
                    exceptional detail preservation. The gallery below showcases diverse panoramic generations 
                    across different environments and conditions. Our method generates temporally consistent long-form videos while maintaining narrative coherence 
                    and visual quality. The collection below demonstrates various scenarios and content types.
                </p> -->
            </div>
        </section>

        <!-- Footer -->
        <footer class="paper-footer">
            <p>
                <strong>Code and Data:</strong> 
                <a href="https://github.com/your-username/your-repo">GitHub Repository</a> | 
                <a href="#dataset-link">Dataset</a>
            </p>
            <p class="updated">Last updated: September 2024</p>
        </footer>
    </main>
</body>
</html>